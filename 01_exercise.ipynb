{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c5ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "151f8ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.3\n",
    "bias = 0.9\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight*X+bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee69b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dde8baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b09ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkPractice(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x +self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51219452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([-0.1057])), ('bias', tensor([-1.7518]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetworkPractice()\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df09e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f440eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7fb697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n",
      "Epoch: 100 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n",
      "Epoch: 200 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n",
      "Epoch: 300 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n",
      "Epoch: 400 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n",
      "Epoch: 500 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n",
      "Epoch: 600 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n",
      "Epoch: 700 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n",
      "Epoch: 800 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n",
      "Epoch: 900 | Train loss: 2.8099725246429443 | Test loss: 3.012810230255127\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87739275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model learned the following values for weights and bias:\n",
      "OrderedDict([('weights', tensor([-0.1057], device='cuda:0')),\n",
      "             ('bias', tensor([-1.7518], device='cuda:0'))])\n",
      "\n",
      "And the original values for weights and bias are:\n",
      "weights: 0.3, bias: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Find our model's learned parameters\n",
    "from pprint import pprint # pprint = pretty print, see: https://docs.python.org/3/library/pprint.html \n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "pprint(model.state_dict())\n",
    "print(\"\\nAnd the original values for weights and bias are:\")\n",
    "print(f\"weights: {weight}, bias: {bias}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
